{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9882864,"sourceType":"datasetVersion","datasetId":6068447}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q -U torch transformers","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-12T09:19:04.747278Z","iopub.execute_input":"2025-09-12T09:19:04.747583Z","iopub.status.idle":"2025-09-12T09:19:09.100495Z","shell.execute_reply.started":"2025-09-12T09:19:04.747551Z","shell.execute_reply":"2025-09-12T09:19:09.099216Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: Could not find a version that satisfies the requirement PIL (from versions: none)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for PIL\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install -q -U faiss-cpu","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T09:21:31.627679Z","iopub.execute_input":"2025-09-12T09:21:31.628001Z","iopub.status.idle":"2025-09-12T09:21:37.829976Z","shell.execute_reply.started":"2025-09-12T09:21:31.627969Z","shell.execute_reply":"2025-09-12T09:21:37.828845Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import CLIPProcessor, CLIPModel\nfrom PIL import Image\nimport pandas as pd\nimport numpy as np\nimport faiss\nimport requests\nimport os\nfrom torch.optim import AdamW\nfrom torch.nn.functional import pad","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T09:56:06.068331Z","iopub.execute_input":"2025-09-12T09:56:06.068787Z","iopub.status.idle":"2025-09-12T09:56:06.075962Z","shell.execute_reply.started":"2025-09-12T09:56:06.068764Z","shell.execute_reply":"2025-09-12T09:56:06.074613Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/mini-product-image-and-text-dataset/data.csv')\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T09:22:15.706882Z","iopub.execute_input":"2025-09-12T09:22:15.707369Z","iopub.status.idle":"2025-09-12T09:22:16.601976Z","shell.execute_reply.started":"2025-09-12T09:22:15.707327Z","shell.execute_reply":"2025-09-12T09:22:16.600690Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"       image                                        description  \\\n0   3238.jpg  Round toed, black sports shoes with red accent...   \n1  43044.jpg  Style Note Built with the breathability and ze...   \n2  54018.jpg  Teal  handbag that has stitch detailing with a...   \n3   8141.jpg  Perfectly stylish, this fastrack analog wrist ...   \n4  22245.jpg  These id mid-top chukka shoes add a fresh spin...   \n\n                                        display name      category  \n0         Puma Men Black 65CC Lo Ducati Sports Shoes  Sports Shoes  \n1                      Nike Men Charcoal Grey Shorts        Shorts  \n2                           Kiara Women Teal Handbag      Handbags  \n3  Fastrack Women Freestyle Sports Analog Steel B...       Watches  \n4                          ID Men Brown Casual Shoes  Casual Shoes  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>description</th>\n      <th>display name</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3238.jpg</td>\n      <td>Round toed, black sports shoes with red accent...</td>\n      <td>Puma Men Black 65CC Lo Ducati Sports Shoes</td>\n      <td>Sports Shoes</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>43044.jpg</td>\n      <td>Style Note Built with the breathability and ze...</td>\n      <td>Nike Men Charcoal Grey Shorts</td>\n      <td>Shorts</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>54018.jpg</td>\n      <td>Teal  handbag that has stitch detailing with a...</td>\n      <td>Kiara Women Teal Handbag</td>\n      <td>Handbags</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8141.jpg</td>\n      <td>Perfectly stylish, this fastrack analog wrist ...</td>\n      <td>Fastrack Women Freestyle Sports Analog Steel B...</td>\n      <td>Watches</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>22245.jpg</td>\n      <td>These id mid-top chukka shoes add a fresh spin...</td>\n      <td>ID Men Brown Casual Shoes</td>\n      <td>Casual Shoes</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T09:23:37.258407Z","iopub.execute_input":"2025-09-12T09:23:37.258850Z","iopub.status.idle":"2025-09-12T09:23:37.264464Z","shell.execute_reply.started":"2025-09-12T09:23:37.258819Z","shell.execute_reply":"2025-09-12T09:23:37.263488Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"model = CLIPModel.from_pretrained('openai/clip-vit-large-patch14').to(device)\nprocessor = CLIPProcessor.from_pretrained('openai/clip-vit-large-patch14')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T09:24:21.025802Z","iopub.execute_input":"2025-09-12T09:24:21.026476Z","iopub.status.idle":"2025-09-12T09:24:37.847168Z","shell.execute_reply.started":"2025-09-12T09:24:21.026426Z","shell.execute_reply":"2025-09-12T09:24:37.845097Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3e8cf90b7a3411cb26d41e3d4b91ab9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.71G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cdb6f7206903427ebf878a9af5da0ba6"}},"metadata":{}},{"name":"stderr","text":"Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/316 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe8bf79bc808497d813ccd07793eeb79"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/905 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96fdeba3b38d4edb96aad01e2de1d41d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b02d8f6f45f847bba69e2a39edfe04fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"118fb36ca5ab4a68a89413a98ac60ee9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e0672198b7b4e5ca7045f712de1b323"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/389 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"741564f9cb674633a8ff65ef5c8fddd7"}},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"row = df.iloc[6]\n\ntxt = str(row['description']) + str(row['display name']) + str(row['category'])\n\ntxt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T10:10:05.156198Z","iopub.execute_input":"2025-09-12T10:10:05.156552Z","iopub.status.idle":"2025-09-12T10:10:05.164492Z","shell.execute_reply.started":"2025-09-12T10:10:05.156528Z","shell.execute_reply":"2025-09-12T10:10:05.163327Z"}},"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"'Crafted for the urban style maven, this brown wallet from lino perros is a must have for those who love organising their wallet space. Dimensions : 10 cm x 19 cm Made of leather Two insert pockets Multi card slots inside One id card holder with a mesh Six more card slots on the other side with an insert pocket The flap has a clasp button Care Wipe with clean, damp cloth to remove dirtLino Perros Women Leather Brown WalletWallets'"},"metadata":{}}],"execution_count":59},{"cell_type":"code","source":"print(processor.tokenizer.model_max_length)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T09:47:57.908096Z","iopub.execute_input":"2025-09-12T09:47:57.908433Z","iopub.status.idle":"2025-09-12T09:47:57.913935Z","shell.execute_reply.started":"2025-09-12T09:47:57.908412Z","shell.execute_reply":"2025-09-12T09:47:57.912761Z"}},"outputs":[{"name":"stdout","text":"77\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"class ProductDataset(Dataset):\n    def __init__(self, metadata, processor):\n        self.metadata = metadata\n        self.processor = processor\n\n    def __len__(self):\n        return len(self.metadata)\n\n    def __getitem__(self, idx):\n        row = self.metadata.iloc[idx]\n        image = Image.open(f\"/kaggle/input/mini-product-image-and-text-dataset/data/{row['image']}\")\n        text = str(row['description']) + str(row['display name']) + str(row['category'])\n        inputs = self.processor(text=[text], images=image, return_tensors='pt', padding=True, truncation=True)\n\n        return{\n            \"input_ids\" : inputs['input_ids'].squeeze(0),\n            \"attention_mask\" : inputs['attention_mask'].squeeze(0),\n            \"pixel_values\" : inputs['pixel_values'].squeeze(0)\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T09:47:29.970668Z","iopub.execute_input":"2025-09-12T09:47:29.971936Z","iopub.status.idle":"2025-09-12T09:47:29.979350Z","shell.execute_reply.started":"2025-09-12T09:47:29.971903Z","shell.execute_reply":"2025-09-12T09:47:29.978356Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"dataset = ProductDataset(df, processor)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T09:47:30.871039Z","iopub.execute_input":"2025-09-12T09:47:30.871389Z","iopub.status.idle":"2025-09-12T09:47:30.876561Z","shell.execute_reply.started":"2025-09-12T09:47:30.871369Z","shell.execute_reply":"2025-09-12T09:47:30.875194Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"sample = dataset[0]\nprint(sample.keys())\n\nprint(sample[\"input_ids\"].shape)\nprint(sample[\"attention_mask\"].shape)\nprint(sample[\"pixel_values\"].shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T09:47:34.104765Z","iopub.execute_input":"2025-09-12T09:47:34.105211Z","iopub.status.idle":"2025-09-12T09:47:34.125611Z","shell.execute_reply.started":"2025-09-12T09:47:34.105186Z","shell.execute_reply":"2025-09-12T09:47:34.124525Z"}},"outputs":[{"name":"stdout","text":"dict_keys(['input_ids', 'attention_mask', 'pixel_values'])\ntorch.Size([77])\ntorch.Size([77])\ntorch.Size([3, 224, 224])\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"print(\"Total samples:\", len(dataset))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T09:47:37.641948Z","iopub.execute_input":"2025-09-12T09:47:37.642274Z","iopub.status.idle":"2025-09-12T09:47:37.647655Z","shell.execute_reply.started":"2025-09-12T09:47:37.642253Z","shell.execute_reply":"2025-09-12T09:47:37.646544Z"}},"outputs":[{"name":"stdout","text":"Total samples: 44441\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"print(\"Pad token id :\", processor.tokenizer.pad_token_id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T09:57:33.923895Z","iopub.execute_input":"2025-09-12T09:57:33.924215Z","iopub.status.idle":"2025-09-12T09:57:33.930016Z","shell.execute_reply.started":"2025-09-12T09:57:33.924193Z","shell.execute_reply":"2025-09-12T09:57:33.928925Z"}},"outputs":[{"name":"stdout","text":"Pad token id : 49407\n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"def custom_collate_func(batch):\n    max_len = max([len(item['input_ids']) for item in batch])\n    \n    padded_input_ids = torch.stack([\n        pad(item['input_ids'], (0, max_len - len(item['input_ids'])), \n        value=processor.tokenizer.pad_token_id) for item in batch\n    ])\n    \n    padded_attention_mask = torch.stack([\n        pad(item['attention_mask'], (0, max_len - len(item['attention_mask'])), \n        value=processor.tokenizer.pad_token_id) for item in batch\n    ])\n\n    pixel_values = torch.stack([item['pixel_values'] for item in batch])\n\n    return{\n        \"input_ids\" : padded_input_ids,\n        \"attention_mask\" : padded_attention_mask,\n        \"pixel_values\" : pixel_values\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T10:05:48.982471Z","iopub.execute_input":"2025-09-12T10:05:48.983691Z","iopub.status.idle":"2025-09-12T10:05:48.991376Z","shell.execute_reply.started":"2025-09-12T10:05:48.983657Z","shell.execute_reply":"2025-09-12T10:05:48.990125Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"dataloader = DataLoader(dataset, batch_size=2, shuffle=True, collate_fn=custom_collate_func)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T10:07:05.645195Z","iopub.execute_input":"2025-09-12T10:07:05.645582Z","iopub.status.idle":"2025-09-12T10:07:05.652337Z","shell.execute_reply.started":"2025-09-12T10:07:05.645556Z","shell.execute_reply":"2025-09-12T10:07:05.650980Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"len(dataloader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T10:07:13.621936Z","iopub.execute_input":"2025-09-12T10:07:13.622231Z","iopub.status.idle":"2025-09-12T10:07:13.629332Z","shell.execute_reply.started":"2025-09-12T10:07:13.622211Z","shell.execute_reply":"2025-09-12T10:07:13.628060Z"}},"outputs":[{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"22221"},"metadata":{}}],"execution_count":54},{"cell_type":"markdown","source":"#### Fine-Tune CLIP","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}